{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34427,
     "status": "ok",
     "timestamp": 1574732309253,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "w1hDk9hDvOH7",
    "outputId": "aecb1d8b-769c-43a3-dd57-d2213f748e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "#Change current working directory to gdrive\n",
    "%cd /gdrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2179,
     "status": "ok",
     "timestamp": 1574732529780,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "BMwGQK7KAd7T",
    "outputId": "52e6ca97-79f3-4e1f-df9d-074fb06fc369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 2)\n",
      "(2070, 17)\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "textfile = r'/gdrive/My Drive/CIS 508/Class/Week6/Comments.csv'\n",
    "textData = pd.read_csv(textfile) #creates a dataframe\n",
    "\n",
    "CustInfofile = r'/gdrive/My Drive/CIS 508/Class/Week6/Customers.csv'\n",
    "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
    "\n",
    "print(textData.shape)\n",
    "print(CustInfoData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1574732531223,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "SWOTk6C1Ao45",
    "outputId": "891dfb65-1d4f-46a0-9d6d-5bc235293ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 16)\n",
      "(2070, 2)\n",
      "0       Cancelled\n",
      "1         Current\n",
      "2         Current\n",
      "3         Current\n",
      "4       Cancelled\n",
      "          ...    \n",
      "2065    Cancelled\n",
      "2066    Cancelled\n",
      "2067    Cancelled\n",
      "2068    Cancelled\n",
      "2069    Cancelled\n",
      "Name: TARGET, Length: 2070, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Extract target column from Customer Info file\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "X_train = CustInfoData.drop(columns=[\"ID\"]) \n",
    "                     \n",
    "print(X_train.shape)\n",
    "print(textData.shape)\n",
    "textData.head()\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1574732720631,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "WiBguQloljam",
    "outputId": "9a99a099-7ab3-4805-ba39-e0de096b3b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 411)\n",
      "['3399', '3g', 'abysmal', 'access', 'accessories', 'adapter', 'add', 'addition', 'additional', 'additonal', 'address', 'aditional', 'adress', 'advertising', 'afraid', 'angeles', 'angry', 'anytime', 'area', 'asap', 'ask', 'asked', 'asking', 'bad', 'basic', 'batery', 'batteries', 'battery', 'believe', 'better', 'bigger', 'billing', 'book', 'bought', 'brain', 'bring', 'built', 'business', 'buttons', 'buy', 'called', 'calls', 'cancel', 'cancer', 'car', 'care', 'carrier', 'causing', 'cc', 'cell', 'certain', 'change', 'changing', 'charge', 'charged', 'charger', 'charges', 'check', 'chip', 'cities', 'city', 'claimed', 'claims', 'clearity', 'cold', 'comapred', 'companies', 'company', 'compared', 'competition', 'competitive', 'complained', 'complaints', 'concept', 'connectivity', 'consisitently', 'consistently', 'constanly', 'contact', 'contacting', 'continued', 'continues', 'contract', 'correct', 'cost', 'couple', 'coverage', 'covered', 'created', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'customer', 'customr', 'date', 'day', 'dead', 'decent', 'defective', 'deos', 'did', 'dies', 'different', 'difficult', 'digitial', 'directions', 'disable', 'does', 'don', 'dont', 'drop', 'dropped', 'dropping', 'dying', 'easier', 'effected', 'encountered', 'end', 'ends', 'enemy', 'equipment', 'everytime', 'evrey', 'exactly', 'expect', 'expected', 'expired', 'explain', 'explained', 'faceplate', 'false', 'family', 'features', 'fed', 'figure', 'figuring', 'finds', 'fine', 'fix', 'fixed', 'forever', 'forwarded', 'forwarding', 'friend', 'functioned', 'furthermore', 'future', 'gave', 'gets', 'getting', 'goat', 'going', 'good', 'great', 'gsm', 'handset', 'happy', 'hard', 'hardly', 'hated', 'hates', 'having', 'hear', 'heard', 'help', 'higher', 'highway', 'hochie', 'holes', 'home', 'hopes', 'horrible', 'house', 'implement', 'improve', 'inadequate', 'included', 'info', 'information', 'ing', 'internet', 'intersection', 'issue', 'june', 'just', 'keeps', 'kids', 'kno', 'know', 'knows', 'lame', 'later', 'lctn', 'learning', 'leroy', 'like', 'line', 'lines', 'list', 'lists', 'local', 'location', 'locatn', 'long', 'los', 'lost', 'lot', 'loves', 'major', 'make', 'manager', 'manual', 'marketing', 'means', 'messaging', 'metropolitian', 'minute', 'minutes', 'misled', 'mistakes', 'model', 'momma', 'moving', 'mr', 'napeleon', 'near', 'nearest', 'needed', 'needs', 'network', 'new', 'news', 'notice', 'number', 'numerous', 'offer', 'offered', 'old', 'omer', 'open', 'options', 'ories', 'ot', 'outbound', 'parts', 'pass', 'pay', 'paying', 'pda', 'people', 'performance', 'person', 'personal', 'phone', 'phones', 'piece', 'plan', 'plans', 'point', 'pointed', 'policy', 'poor', 'possible', 'probably', 'problem', 'problems', 'properly', 'provide', 'provisioning', 'purposes', 'rate', 'rater', 'rates', 'realize', 'realizes', 'really', 'reason', 'received', 'receiving', 'reception', 'recption', 'reenter', 'referred', 'related', 'rep', 'replace', 'replaced', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roaming', 'roll', 'rubbish', 'rude', 'said', 'sales', 'says', 'screening', 'sees', 'self', 'send', 'sending', 'service', 'shitty', 'shut', 'sign', 'signal', 'signed', 'significantly', 'simm', 'simply', 'site', 'slow', 'sold', 'soon', 'speak', 'speed', 'started', 'static', 'stole', 'store', 'stuff', 'stupid', 'substantively', 'subtracted', 'sucked', 'sucks', 'suggested', 'suggestion', 'supervisor', 'support', 'sure', 'surprised', 'suspect', 'suspend', 'switch', 'switched', 'teach', 'technical', 'telling', 'terrible', 'test', 'text', 'thinking', 'thinks', 'thought', 'ticket', 'till', 'time', 'tired', 'today', 'toilet', 'told', 'tones', 'towers', 'transeffered', 'transfe', 'transferred', 'traveling', 'travels', 'tried', 'trust', 'try', 'turn', 'uncomfortable', 'understand', 'unhappy', 'unlimited', 'unreliable', 'unwilling', 'upset', 'usage', 'use', 'useless', 'uses', 'using', 'value', 'vm', 'wa', 'wait', 'waiting', 'want', 'wanted', 'wants', 'waste', 'way', 'weak', 'web', 'website', 'week', 'wholes', 'wife', 'willing', 'wished', 'wll', 'wold', 'work', 'worked', 'working', 'works', 'worse', 'worst', 'wrong', 'xvyx', 'year', 'york']\n"
     ]
    }
   ],
   "source": [
    "#Do Bag-Of-Words model - Term - Document Matrix\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "#count_vect = CountVectorizer()\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "TD_counts = count_vect.fit_transform(textData.Comments)\n",
    "print(TD_counts.shape)\n",
    "TD_counts.dtype\n",
    "print(count_vect.get_feature_names())\n",
    "#print(TD_counts)\n",
    "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
    "#print(DF_TD_Counts)\n",
    "export_csv = DF_TD_Counts.to_csv(r'/gdrive/My Drive/CIS 508/Class/Week6/TD_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1574732941984,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "pd8TZYnAxQbP",
    "outputId": "42c7805d-e773-419c-f5ac-5e09bfbf3eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 411)\n",
      "      0    1    2    3         4    5    ...  405  406  407  408  409  410\n",
      "0     0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1     0.0  0.0  0.0  0.0  0.276346  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2     0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3     0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4     0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...   ...  ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "2065  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2066  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2067  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2068  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2069  0.0  0.0  0.0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[2070 rows x 411 columns]\n"
     ]
    }
   ],
   "source": [
    "#Compute TF-IDF Matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
    "print(DF_TF_IDF)\n",
    "export_csv= DF_TF_IDF.to_csv(r'/gdrive/My Drive/CIS 508/Class/Week6/TFIDF_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1574733014916,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "geVCLka8xxjf",
    "outputId": "6186ab66-0364-4441-ac95-50efe8d5dfea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.634783\n",
      "Confusion Matrix:\n",
      "[[ 101  703]\n",
      " [  53 1213]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.66      0.13      0.21       804\n",
      "     Current       0.63      0.96      0.76      1266\n",
      "\n",
      "    accuracy                           0.63      2070\n",
      "   macro avg       0.64      0.54      0.49      2070\n",
      "weighted avg       0.64      0.63      0.55      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on text data\n",
    "clf=RandomForestClassifier()\n",
    "RF_text = clf.fit(X_train_tfidf,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(X_train_tfidf, y_train)))\n",
    "rf_predictions = clf.predict(X_train_tfidf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1478,
     "status": "ok",
     "timestamp": 1574733225374,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "Fq_7eeQOz7xk",
    "outputId": "91541c71-adae-4cbe-9e9d-a2185be87fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 17)\n",
      "(2070, 16)\n",
      "(2070, 427)\n",
      "        ID Sex Status  Children  Est_Income  ...  406  407  408  409  410\n",
      "0        1   F      S         1    38000.00  ...  0.0  0.0  0.0  0.0  0.0\n",
      "1        6   M      M         2    29616.00  ...  0.0  0.0  0.0  0.0  0.0\n",
      "2        8   M      M         0    19732.80  ...  0.0  0.0  0.0  0.0  0.0\n",
      "3       11   M      S         2       96.33  ...  0.0  0.0  0.0  0.0  0.0\n",
      "4       14   F      M         2    52004.80  ...  0.0  0.0  0.0  0.0  0.0\n",
      "...    ...  ..    ...       ...         ...  ...  ...  ...  ...  ...  ...\n",
      "2065  3821   F      S         0    78851.30  ...  0.0  0.0  0.0  0.0  0.0\n",
      "2066  3822   F      S         1    17540.70  ...  0.0  0.0  0.0  0.0  0.0\n",
      "2067  3823   F      M         0    83891.90  ...  0.0  0.0  0.0  0.0  0.0\n",
      "2068  3824   F      M         2    28220.80  ...  0.0  0.0  0.0  0.0  0.0\n",
      "2069  3825   F      S         0    28589.10  ...  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[2070 rows x 427 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge files\n",
    "#print(type(X_train_tfidf)) #This is a sparse matrix\n",
    "convert_To_Dataframe = pd.DataFrame(X_train_tfidf.toarray())\n",
    "print(CustInfoData.shape)\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "print(X_train.shape)\n",
    "#X_train = CustInfoData.drop(columns=[\"ID\"]) \n",
    "combined=pd.concat([X_train, convert_To_Dataframe], axis=1)\n",
    "print(combined.shape)\n",
    "print(combined)\n",
    "export_csv= combined.to_csv(r'/gdrive/My Drive/CIS 508/Class/Week6/combined5.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1311,
     "status": "ok",
     "timestamp": 1574733243217,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "EPmJYiWrPkRG",
    "outputId": "a3a7fbfc-5144-4558-afb8-c9304a04a095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
      "(2070, 435)\n"
     ]
    }
   ],
   "source": [
    "#Do one Hot encoding for categorical features\n",
    "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
    "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
    "print(X_cat)\n",
    "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
    "print(combined_one_hot.shape)\n",
    "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/CIS 508/Class/Week6/combined_one_hot.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1574733248133,
     "user": {
      "displayName": "Nithin George",
      "photoUrl": "",
      "userId": "01993130238656705094"
     },
     "user_tz": 420
    },
    "id": "DEMpFKQAVuV1",
    "outputId": "bb8e1bc7-2f8d-40a7-e860-4be56a5ddcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.993237\n",
      "Confusion Matrix:\n",
      "[[ 801    3]\n",
      " [  11 1255]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.99      1.00      0.99       804\n",
      "     Current       1.00      0.99      0.99      1266\n",
      "\n",
      "    accuracy                           0.99      2070\n",
      "   macro avg       0.99      0.99      0.99      2070\n",
      "weighted avg       0.99      0.99      0.99      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on combined data\n",
    "#clf1=RandomForestClassifier()\n",
    "RF_Comb = clf.fit(combined_one_hot,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(combined_one_hot, y_train)))\n",
    "rf_predictions = clf.predict(combined_one_hot)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Mining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
